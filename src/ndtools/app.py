"""
This module provides functionality to process duplicate media files.
"""

import json
import os
import sys
import unicodedata

import jsonpickle
from dotenv import find_dotenv, load_dotenv

from ndtools.db import NavidromeDb
from ndtools.model import MediaFile
from ndtools.utils import CLI, DotDict
from ndtools.utils import PrintUtils as PU


class DuplicateProcessor:
    """
    This class processes duplicate media files.

    Attributes:
        db (NavidromeDb): The database connection to interact with the Navidrome database.
        dups_input (dict): A dictionary containing the raw duplicate media files references from Beets.
        media_files (dict): A dictionary containing the enhanced duplicate media files with data from Navidrome.
        stats (DotDict): A dictionary containing statistics about the processing of duplicate media files.
        output_folder (str): The path to the output folder where processed files will be saved.
    """

    DUPLICATES_INPUT_FILE = "beets-duplicates.json"

    db: NavidromeDb
    dups_input: dict
    dups_media_files: dict
    stats: DotDict
    errors: list
    output_folder: str
    source_base: str
    target_base: str

    def __init__(self, db: NavidromeDb, output_folder: str, source_base: str, target_base: str):
        """
        Initialize the DuplicateProcessor with a database and an input file containing duplicate media files.

        The input JSON file with media references is generated by the Beets `duplicatez` plugin.

        Args:
            db (NavidromeDb): The Navidrome data access object.
            output_folder (str): Path to the output folder where processed files are saved.
            source_base (str): Paths in the JSON file are relative to this path.
            target_base (str): The actual location in the Navidrome music library.
        """
        self.output_folder = output_folder
        self.db = db
        self.source_base = source_base
        self.target_base = target_base

        # Path to JSON file generated by the Beets `duplicatez` plugin.
        input_file_path = output_folder + "/" + DuplicateProcessor.DUPLICATES_INPUT_FILE
        # Read the input JSON file containing duplicate media files references from Beets.
        with open(input_file_path, "r", encoding="utf-8") as file:
            self.dups_input = json.load(file)
        if not self.dups_input:
            PU.red(f"No duplicates found in input file '{input_file_path}'")
            sys.exit(1)

        # Init media file duplicates dictionary for holding processing output.
        self.dups_media_files = {}

        # Init logging objects.
        self.errors = []
        self.stats = DotDict(
            {
                "duplicate_records": 0,
                "duplicate_files": 0,
                "media_files": 0,
                "file_annotations": 0,
                "media_files_deletable": 0,
            }
        )

    def merge_and_store_annotations(self):
        """
        Merge annotations per duplicate records and store them to the database.
        """
        self._replace_base_path()
        self._query_media_data()
        PU.print("---------------------------------------------------------------------------------------------")

        # Check for errors before proceeding. If there are errors, ask the user if they want to continue.
        if len(self.errors) > 0:
            PU.red("Errors encountered during processing. Please review the error log.")
            PU.red("Do you want to continue anyway (not recommended)?")
            CLI.ask_continue()

        # Ask user if they want to continue with merging and storing annotations.
        if CLI.ask_continue(
            "m",
            "Do you want to continue with merging and storing annotations? Press 'm' or any other key to skip.",
            exit=False,
        ):
            self._merge_annotation_list()
            self._save_all_annotations()
        PU.print("---------------------------------------------------------------------------------------------")
        self.eval_deletable_duplicates()
        PU.print("---------------------------------------------------------------------------------------------")

    def eval_deletable_duplicates(self):
        """
        Detect deletable duplicate files based on the provided criteria.
        """
        for key, dups in self.dups_media_files.items():
            PU.bold(f"\nEvaluating {len(dups)} duplicates for: {key}")
            keepable = self._get_keepable_media(dups)
            PU.green(f"Found keepable: {keepable}", 1)

        file_path = self.output_folder + "/duplicates-with-keepers.json"
        with open(file_path, "w", encoding="utf-8") as file:
            file.write(jsonpickle.encode(self.dups_media_files, indent=4))
        print(f"Stored deletables and keepers to '{file_path}'")

    def delete_duplicates(self):
        """
        Delete duplicate files from the Navidrome database and from the file system.
        """
        pass

    def _get_keepable_media(self, dups: list[MediaFile]) -> MediaFile:
        """
        Recursively determine which file is keepable based on the criteria.

        Args:
            dups (MediaFile): A list of duplicate media files to evaluate for a keepable.

        Returns:
            MediaFile: The media file to keep.
        """

        # Define the criteria for keepable media
        def is_keepable(this: MediaFile, that: MediaFile) -> MediaFile:
            PU.print(f"COMPARING {this.path} <=> {that.path}", 1)

            # If the files album already contains a keepable, we wanna keep all the items
            left = this.album and this.album.has_keepable
            right = that.album and that.album.has_keepable
            PU.print(f"Compare if albums contain a keepable: {left} || {right}", 1)
            if left != right:
                if left:
                    return this
                elif right:
                    return that
            # Skip, if they are the same

            # Having a MusicBrainz recording ID is keepable
            left = this.mbz_recording_id is not None
            right = that.mbz_recording_id is not None
            PU.print(f"Compare MusicBrainz recording ID: {left} || {right}", 1)
            if left != right:
                if left:
                    return this
                elif right:
                    return that
            # Skip, if they are the same

            # Having track numbers is keepable
            left = this.track_number > 0
            right = that.track_number > 0
            PU.print(f"Compare track numbers: {left} || {right}", 1)
            if left != right:
                if left:
                    return this
                elif right:
                    return that
            # Skip, if they are the same

            # Higher bitrate is keepable
            left = this.bitrate
            right = that.bitrate
            PU.print(f"Compare bitrate: {left} || {right}", 1)
            if left > right:
                return this
            elif left < right:
                return that
            # Skip, if they are the same

            # Year info is keepable
            left = this.year and this.year > 0
            right = that.year and this.year > 0
            PU.print(f"Compare year info: {left} || {right}", 1)
            if left != right:
                if left:
                    return this
                elif right:
                    return that
            # Skip, if they are the same

            # If no conditition matches, it doesn't matter which one we take
            PU.warn("No condition matched, keeping the other one (that)")
            self.errors.append({"warning": "No condition matched, keeping 'that'", "this": this, "that": that})
            return that

        if len(dups) == 1:
            # Keepable if there is only one duplicate
            dups[0].album.keepable = True
            return dups[0]
        else:
            # Get the last item of the dups list:
            this = dups[-1]
            that = dups[-2]
            keepable = is_keepable(this, that)
            removed: MediaFile = None

            child_dups: list[MediaFile] = dups[:-2]
            if keepable == this:
                child_dups.append(this)
                removed = that
            else:
                child_dups.append(that)
                removed = this

            keepable.album.has_keepable = True
            removed.deletable = True
            self.stats.media_files_deletable += 1
            PU.print(f"Deletable: {removed}", 1)
            return self._get_keepable_media(child_dups)

    def _replace_base_path(self):
        """
        Replace the music library base location with the actual location.

        This is required since the base paths of files may differ between the Beets and Navidrome library.
        """
        if not self.source_base or not target_base:
            PU.orange("Skipping base path update")
            return
        if self.source_base == self.target_base:
            PU.orange("Skipping base path update as target equals source")
            return

        for paths in self.dups_input.values():
            for i, item in enumerate(paths):
                paths[i] = item.replace(self.source_base, self.target_base, 1)
        PU.green(f"Updated all base paths from '{self.source_base}' to '{self.target_base}'")

    def _query_media_data(self):
        """
        Query the Navidrome database for each duplicate file and get all relevant data.
        """
        for key in self.dups_input.keys():
            PU.print("")
            PU.print(f"[*] Processing duplicate {key}")
            files = self.dups_input.get(key)
            self.stats.duplicate_records += 1

            # Initialize the list for this key if it doesn't exist.
            if not self.dups_media_files.get(key):
                self.dups_media_files[key] = []

            for file in files:
                self.stats.duplicate_files += 1
                # Normalize Unicode characters in the file path. Otherwise characters like `á` (`\u0061\u0301`)
                # and `á` (`\u00e1`) are not threaded as the same.
                file = unicodedata.normalize("NFC", file)

                PU.print(f"    Query {file}", 0)
                media: MediaFile = db.get_media(file)
                self.dups_media_files[key].append(media)
                self._log_info(file, media)

    def _merge_annotation_list(self):
        """
        Merge data of all media file annotations referred to as duplicates.
        """
        for key, dups in self.dups_media_files.items():
            PU.green(f"Merging {key} with {len(dups)} duplicates...")
            if len(dups) < 2:
                PU.orange("> No duplicates to be merged. Skipping.", 1)
                continue
            for dup in dups[1 : len(dups)]:
                self._merge_annotation_data(dups[0], dup)
            PU.green("> Merged successfully.", 1)

    def _merge_annotation_data(self, a: MediaFile, b: MediaFile):
        """
        Merge annotation data of two MediaFile objects.
        """
        aa = a.annotation
        ba = b.annotation
        PU.print(f"Merging annotations for {aa} and {ba} ...")

        if aa and ba:
            # Combine play counts
            aa.play_count += int(ba.play_count)
            ba.play_count = aa.play_count
            PU.print(f"Combined play count: {aa.play_count}", 1)
            if aa.play_date and ba.play_date:
                if aa.play_date > ba.play_date:
                    ba.play_date = aa.play_date
                else:
                    aa.play_date = ba.play_date
            PU.print(f"Updated play date: {aa.play_date}", 1)

            # Keep the better rating
            if aa.rating and ba.rating:
                if aa.rating > ba.rating:
                    ba.rating = aa.rating
                else:
                    aa.rating = ba.rating
            elif aa.rating and not ba.rating:
                ba.rating = aa.rating
            elif not aa.rating and ba.rating:
                aa.rating = ba.rating
            PU.print(f"Merged rating: {aa.rating}", 1)

            # If one is starred, both are starred
            if aa.starred and not ba.starred:
                ba.starred = True
                ba.starred_at = aa.starred_at
            elif not aa.starred and ba.starred:
                aa.starred = True
                aa.starred_at = ba.starred_at
            PU.print(f"Is starred: {aa.starred}", 1)

    def _save_all_annotations(self):
        """
        Save all annotations of all media file duplicates to the database.
        """
        for _, dups in self.dups_media_files.items():
            for media in dups:
                self.db.store_annotation(media.annotation)

    def _log_info(self, file_path: str, media: MediaFile):
        """
        Log information about the media file.
        """
        if media:
            PU.green(f"└─ {media}", 1)
            self.stats.media_files += 1
            if media.annotation:
                PU.green(f"└───── {media.annotation}", 2)
                self.stats.file_annotations += 1
            if media.artist:
                PU.green(f"└───── {media.artist}", 2)
                if media.artist.annotation:
                    PU.green(f"└───── {media.artist.annotation}", 3)
            else:
                self.errors.append({"error": "artist not found", "path": file_path, "media": media})
                PU.red("└───── Artist not found in database!", 2)
            if media.album:
                PU.green(f"└───── {media.album}", 2)
                if media.album.annotation:
                    PU.green(f"└───── {media.album.annotation}", 3)
            else:
                # This is not seen as an error because not all media files have an album
                PU.orange("└───── Album not found in database!", 2)
        else:
            self.errors.append({"error": "media file not found", "path": file_path})
            PU.red("└───── Media file not found in database!", 1)

    def print_stats(self):
        PU.print("")
        PU.print("-----------------------------------------------------")
        PU.green(" STATISTICS")
        PU.print("-----------------------------------------------------")
        PU.print("")
        PU.green(" Duplicates:")
        PU.green(f"     Records: {self.stats.duplicate_records}")
        PU.green(f"     Files: {self.stats.duplicate_files}")
        PU.print("")
        PU.green(" Media files:")
        PU.green(f"     Found: {self.stats.media_files}")
        PU.green(f"     Annotations: {self.stats.file_annotations}")
        PU.green(f"     Deletables: {self.stats.media_files_deletable}")
        PU.print("")
        PU.green(f" Artists: {len(self.db.artists)}")
        PU.green(f" Albums: {len(self.db.albums)}")
        PU.print("")

    def export_errors(self):
        PU.print("-----------------------------------------------------")
        PU.green(" ERRORS")
        PU.print("-----------------------------------------------------")
        if len(self.errors) > 0:
            error_file = self.output_folder + "/errors.json"
            PU.red(f"Exporting {len(self.errors)} errors to {error_file} ...")
            with open(error_file, "w") as f:
                json.dump(self.errors, f, indent=4)
            PU.red("Done!")
        else:
            PU.green(" No errors found.")
        PU.print("-----------------------------------------------------")


if __name__ == "__main__":
    # Read the action argument from the command line
    action = sys.argv[1] if len(sys.argv) > 1 else None
    action = action.split("action=")[1]

    load_dotenv(find_dotenv())

    config_dir = None
    report_dir = None
    music_dir = None
    source_base = None
    target_base = None

    if os.getenv("DIR_CONFIG"):
        config_dir = os.getenv("DIR_CONFIG")
    if os.getenv("DIR_OUTPUT"):
        report_dir = os.getenv("DIR_OUTPUT")
    if os.getenv("DIR_MUSIC"):
        music_dir = os.getenv("DIR_MUSIC")
    if os.getenv("BEETS_BASE_PATH"):
        source_base = os.getenv("BEETS_BASE_PATH")
    if os.getenv("NAVIDROME_BASE_PATH"):
        target_base = os.getenv("NAVIDROME_BASE_PATH")

    db = NavidromeDb(f"{config_dir}/navidrome/navidrome.db")
    processor = DuplicateProcessor(db, report_dir, source_base, target_base)

    if action == "merge-annotations":
        processor.merge_and_store_annotations()
        processor.print_stats()
        processor.export_errors()
    elif action == "eval-deletable-duplicates":
        processor.eval_deletable_duplicates()
    elif action == "delete-duplicates":
        processor.delete_duplicates()
    else:
        PU.red(f"{action}: Invalid action specified")
